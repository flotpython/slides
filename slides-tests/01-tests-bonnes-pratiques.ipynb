{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "<div class=\"licence\">\n",
    "<span>Licence CC BY-NC-ND</span>\n",
    "<span>Thierry Parmentelat &amp; Arnaud Legout</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Python\n",
    "\n",
    "## bonnes pratiques de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### un mot sur l'instruction `assert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-cdd76bffc605>\", line 5, in <module>\n",
      "    assert x < 0\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "x = 10\n",
    "\n",
    "try: \n",
    "    assert x < 0\n",
    "except Exception:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### un mot sur `assert`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "`assert expression` est équivalent à\n",
    "\n",
    "```\n",
    "if __debug__: \n",
    "    if not expression: raise AssertionError \n",
    "```\n",
    "\n",
    "* `__debug__` est `True` par défaut  \n",
    "  et `False` si l’interpréteur est lancé avec l’option `–O`\n",
    "* on ne peut pas modifier à la main la variable `__debug__`\n",
    "* avec l’option `–O`, tous les `assert` sont enlevés lors de la compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# catégories de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* on trouve souvent dans la littérature des distinctions comme\n",
    "  * test unitaires\n",
    "  * test d'intégration\n",
    "  * tests système, etc...\n",
    "  * (non-régression)\n",
    "* peuvent faire du sens au niveau d'un projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## catégorisation - suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* mais pas sûr que ces distinctions soient pertinentes/utiles\n",
    "  * pour comparer deux projets\n",
    "\n",
    "* exemple\n",
    "  * un test système pour une librairie d'algèbre linéaire\n",
    "  * peut être plus simple à mettre en place\n",
    "  * qu'un test unitaire pour un système de téléphonie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pourquoi automatiser les tests ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* nécessité de tester au moins une fois\n",
    "* un tout petit changement peut tout casser\n",
    "* il faut donc **tout tester à chaque changement**\n",
    "* de ce point de vue tous les tests sont de **non-régression**\n",
    "  * sauf la première fois\n",
    "  * lorsqu'on teste le test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## catégories de test - pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* il faut que les scénarii de test soient reproductibles\n",
    "  * nécessaire de contrôler entièrement l'environnement\n",
    "* il reste une catégorisation objective\n",
    "  * selon la complexité de l'environnement de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## aujourd'hui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* grâce à des outils comme\n",
    "  * docker - pour la gestion des environnements\n",
    "  * et l'intégration continue (webhooks gitlab/github)\n",
    "  * (présentation séparée)\n",
    "* il est à la portée d'un *simple individu* de \n",
    "  * mettre en place des tests **systématiques** très complets \n",
    "  * tant que tous les composants tiennent dans une VM\n",
    "* et même, au prix d'un effort un peu supérieur\n",
    "  * d'orchestrer plusieurs VMs\n",
    "  * sur un cloud comme amazon ou autre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### écrire les tests en même temps que le code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* c'est pourquoi il est entendu que\n",
    "* on écrit les tests en même temps que le code\n",
    "  * que ce soit pour du code from scratch\n",
    "  * ou des corrections de bug\n",
    "* nécessaire mais généralement pas suffisant\n",
    "  * intégration/système\n",
    "* trouver le bon compromis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# librairies de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* les frameworks de test les plus cités\n",
    "  * `unittest` - dans la librairie standard\n",
    "  * `pytest` - à installer avec `pip`\n",
    "  * (`nose` - à installer avec `pip` - pas présenté)\n",
    "* la tendance est en faveur de `pytest`\n",
    "* signalons en outre `doctest` (voir partie sur la doc)\n",
    "  * beaucoup moins puissant\n",
    "  * mais avantage de grouper code et test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `unittest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "fait partie de la librairie standard; contient:\n",
    "\n",
    "* une interface orientée objet\n",
    "  * pour l'écriture des tests\n",
    "* une fonctionnalité *runner*\n",
    "  * exécution et présentation des résultats\n",
    "* et une fonctionnalité *discover*\n",
    "  * recherche de tous les test-cases\n",
    "  * e.g. dans tout un package ou module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\n",
      "def pgcd(a, b):\n",
      "    \"\"\"\n",
      "    Le pgcd de a et b par l'algorithme d'Euclide\n",
      "    >>> pgcd(42, 30)\n",
      "    6\n",
      "    >>> pgcd(30, 42)\n",
      "    6\n",
      "    \"\"\"\n",
      "    if b > a :\n",
      "        a, b = b, a\n",
      "    while True:\n",
      "        r = a % b\n",
      "        if r == 0:\n",
      "            return b\n",
      "        a, b = b, r\n"
     ]
    }
   ],
   "source": [
    "!cat library/pgcd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "from unittest import TestCase\n",
      "\n",
      "class TestPgcd(TestCase):\n",
      "\n",
      "    def test_upper(self):\n",
      "        self.assertEqual(pgcd(42, 30), 6)\n",
      "\n",
      "    def test_lower(self):\n",
      "        self.assertEqual(pgcd(30, 42), 6)\n"
     ]
    }
   ],
   "source": [
    "!cat tests/test_pgcd_unittest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## à noter\n",
    "\n",
    "* ces tests sont simplistes (⇔ à ceux en doctest)\n",
    "  * mais on faire beaucoup plus !\n",
    "* les vérifications sont faites à partir de **méthodes**\n",
    "  * de la classe `TestCase` - ici `assertEqual`\n",
    "* notamment on peut vérifier qu'un appel lève une exception \n",
    "  * avec `assertRaises` et similaires\n",
    "* ou que deux valeurs sont presques égales (précision flottants)\n",
    "  * avec `AssertAlmostEqual`\n",
    "* ou qu'un string matche une expression régulière\n",
    "  * avec `assertRegex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## comment sont découverts les tests\n",
    "\n",
    "* la convention de nommer les objets en `test_*`:\n",
    "  * le module s'appelle `test_pgcd.py`\n",
    "  * la méthode s'appelle `test_upper` \n",
    "  * c'est important pour les fonctions de découverte\n",
    "* la classe hérite de `TestCase` \n",
    "  * c'est pourquoi son nom importe peu\n",
    "  * (les noms de classes sont `EnChasseMixte`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## quoi en faire\n",
    "\n",
    "* point d'entrée `python3 -m unittest`\n",
    "* on peut lui passer un module, une classe ou une méthode\n",
    "  * ou une liste de .. évidemment\n",
    "* ou le laisser trouver tous les tests dans un module\n",
    "  * fonction `discover`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# si on lui passe une méthode précise, seul ce test case est lancé\n",
    "!python3 -m unittest tests.test_pgcd_unittest.TestPgcd.test_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# si on lui précise le module, les deux tests sont lancés\n",
    "!python3 -m unittest tests.test_pgcd_unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_lower (tests.test_pgcd_unittest.TestPgcd) ... ok\n",
      "test_upper (tests.test_pgcd_unittest.TestPgcd) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# idem avec l'option -v \n",
    "!python3 -m unittest -v tests.test_pgcd_unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\t\t test_pgcd_pytest.py\t     test_pgcd_unittest.py\n",
      "__pycache__\t\t test_pgcd_pytest_broken.py  test_pgcd_unittest_fix1.py\n",
      "test_pgcd_nose_class.py  test_pgcd_pytest_class.py   test_pgcd_unittest_fix2.py\n",
      "test_pgcd_nose_deco.py\t test_pgcd_pytest_raise.py\n"
     ]
    }
   ],
   "source": [
    "# en fait dans le répertoire tests/ \n",
    "# il y a plus de testcases que cela\n",
    "!ls tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_lower (test_pgcd_unittest.TestPgcd) ... ok\n",
      "test_upper (test_pgcd_unittest.TestPgcd) ... ok\n",
      "test_lower (test_pgcd_unittest_fix1.TestPgcd) ... méthode/fixture - setup - test_pgcd_unittest_fix1.TestPgcd.test_lower\n",
      "méthode/fixture - tearDown - test_pgcd_unittest_fix1.TestPgcd.test_lower\n",
      "ok\n",
      "test_upper (test_pgcd_unittest_fix1.TestPgcd) ... méthode/fixture - setup - test_pgcd_unittest_fix1.TestPgcd.test_upper\n",
      "méthode/fixture - tearDown - test_pgcd_unittest_fix1.TestPgcd.test_upper\n",
      "ok\n",
      "classe/fixture - setup - TestPgcd\n",
      "test_lower (test_pgcd_unittest_fix2.TestPgcd) ... ok\n",
      "test_upper (test_pgcd_unittest_fix2.TestPgcd) ... ok\n",
      "classe/fixture - tearDown - TestPgcd\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# on lance la découverte sur tout le package...\n",
    "# du coup il va trouver les autres versions du même test\n",
    "# que nous allons voir tout de suite\n",
    "!python3 -m unittest discover -v tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## fixtures\n",
    "\n",
    "* c'est quoi une fixture ?\n",
    "* le code pour mettre le système dans un état initial connu\n",
    "  * assez rustique dans `unittest`\n",
    "* on veut pouvoir définir simplement\n",
    "  * une façon d'initialiser/nettoyer (setup/teardown)\n",
    "* à l'entrée et la sortie de **tout le scénario**\n",
    "  * `setUpClass/tearDownClass`\n",
    "* et aussi à l'entrée et la sortie de **chaque test**\n",
    "  * `setUp`/`tearDown`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `setUp`/`tearDown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "from unittest import TestCase\n",
      "\n",
      "class TestPgcd(TestCase):\n",
      "\n",
      "    # en définissant ces deux méthodes\n",
      "    # on obtient du code qui est exécuté\n",
      "    # avant et après CHAQUE TEST\n",
      "    # soit donc ici DEUX FOIS\n",
      "    def setUp(self):\n",
      "        print(\"méthode/fixture - setup - {}\".format(self.id()))\n",
      "\n",
      "    def tearDown(self):\n",
      "        print(\"méthode/fixture - tearDown - {}\".format(self.id()))\n",
      "    \n",
      "    def test_upper(self):\n",
      "        self.assertEqual(pgcd(42, 30), 6)\n",
      "\n",
      "    def test_lower(self):\n",
      "        self.assertEqual(pgcd(30, 42), 6)\n"
     ]
    }
   ],
   "source": [
    "!cat tests/test_pgcd_unittest_fix1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "méthode/fixture - setup - tests.test_pgcd_unittest_fix1.TestPgcd.test_lower\n",
      "méthode/fixture - tearDown - tests.test_pgcd_unittest_fix1.TestPgcd.test_lower\n",
      ".méthode/fixture - setup - tests.test_pgcd_unittest_fix1.TestPgcd.test_upper\n",
      "méthode/fixture - tearDown - tests.test_pgcd_unittest_fix1.TestPgcd.test_upper\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests.test_pgcd_unittest_fix1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `setUpClass` et `teardownClass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "from unittest import TestCase\n",
      "\n",
      "class TestPgcd(TestCase):\n",
      "\n",
      "    # en définissant ces deux méthodes\n",
      "    # on obtient du code qui est exécuté\n",
      "    # avant et après LE PAQUET de tests\n",
      "    # soit donc UNE SEULE FOIS\n",
      "    @classmethod\n",
      "    def setUpClass(cls):\n",
      "        print(\"classe/fixture - setup - {}\".format(cls.__name__))\n",
      "\n",
      "    @classmethod\n",
      "    def tearDownClass(cls):\n",
      "        print(\"classe/fixture - tearDown - {}\".format(cls.__name__))\n",
      "    \n",
      "    def test_upper(self):\n",
      "        self.assertEqual(pgcd(42, 30), 6)\n",
      "\n",
      "    def test_lower(self):\n",
      "        self.assertEqual(pgcd(30, 42), 6)\n"
     ]
    }
   ],
   "source": [
    "!cat tests/test_pgcd_unittest_fix2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe/fixture - setup - TestPgcd\n",
      "..classe/fixture - tearDown - TestPgcd\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m unittest tests.test_pgcd_unittest_fix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `unittest` - autres traits\n",
    "\n",
    "* on peut aussi définir `setUpModule`/`tearDownModule` \n",
    "  * au niveau du module..\n",
    "* avec les décorateurs `skip` `skipIf` `skipUnless`\n",
    "  * on peut passer des tests en fonction de l'environnement\n",
    "  * typiquement de l'operating system\n",
    "  * ou de la version python ...\n",
    "  * on peut aussi passer un test pendant le run avec [`skipTest()`](https://docs.python.org/3.5/library/unittest.html#unittest.TestCase.skipTest)\n",
    "* avec la notion de [`subTest`](https://docs.python.org/3.5/library/unittest.html#unittest.TestCase.subTest)\n",
    "  * on peut éviter que la première assertion \n",
    "  * ne cause la fin de toute la méthode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `unittest` - épilogue\n",
    "\n",
    "* bref, c'est très complet\n",
    "* mais un tout petit peu compliqué\n",
    "* par exemple\n",
    "  * le niveau 'classe' peut être jugé superflu\n",
    "  * dans notre exemple, avec un layout tout bête\n",
    "  * un test = niveau 4 !\n",
    "\n",
    "`tests.test_pgcd_unittest.TestPgcd.test_lower`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `pytest` - introduction\n",
    "\n",
    "* philosophie générale\n",
    "  * \"no boilerplate, no required api\" \n",
    "* supporte *aussi* les tests écrits en `unittest`\n",
    "* format de sortie le plus lisible\n",
    "  * notamment pour les tests qui ne passent pas\n",
    "  * entre autres une raison de son succès\n",
    "* [la documentation sur readthedocs](http://doc.pytest.org/en/latest/assert.html)\n",
    "  * système de plugins disponible  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## installation\n",
    "\n",
    "```\n",
    "pip3 install pytest\n",
    "```\n",
    "\n",
    "* expose une commande `py.test` (⇔ `python3 -m pytest`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## lancement des tests / discovery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 17 items                                                             \u001b[0m\n",
      "\n",
      "tests/test_pgcd_nose_class.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                         [ 11%]\u001b[0m\n",
      "tests/test_pgcd_nose_deco.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                          [ 23%]\u001b[0m\n",
      "tests/test_pgcd_pytest.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                             [ 35%]\u001b[0m\n",
      "tests/test_pgcd_pytest_broken.py \u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                      [ 47%]\u001b[0m\n",
      "tests/test_pgcd_pytest_class.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                       [ 58%]\u001b[0m\n",
      "tests/test_pgcd_pytest_raise.py \u001b[32m.\u001b[0m\u001b[36m                                        [ 64%]\u001b[0m\n",
      "tests/test_pgcd_unittest.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                           [ 76%]\u001b[0m\n",
      "tests/test_pgcd_unittest_fix1.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                      [ 88%]\u001b[0m\n",
      "tests/test_pgcd_unittest_fix2.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                      [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m__________________________________ test_upper __________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_upper():\u001b[0m\n",
      "\u001b[1m        # broken test on purpose\u001b[0m\n",
      "\u001b[1m>       assert pgcd(42, 30) == 7\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 6 == 7\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 6 = pgcd(42, 30)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_pgcd_pytest_broken.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m===================== 1 failed, 16 passed in 0.30 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# tout simplement\n",
    "!py.test tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1 -- /Users/tparment/git/flotpython-slides/venv/bin/python3.7\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest.py::test_upper \u001b[32mPASSED\u001b[0m\u001b[36m                             [ 50%]\u001b[0m\n",
      "tests/test_pgcd_pytest.py::test_lower \u001b[32mPASSED\u001b[0m\u001b[36m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ou seulement sur un module, une classe, un testcase\n",
    "!py.test -v tests/test_pgcd_pytest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1 -- /Users/tparment/git/flotpython-slides/venv/bin/python3.7\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest.py::test_upper \u001b[32mPASSED\u001b[0m\u001b[36m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test -v tests/test_pgcd_pytest.py::test_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# exemple simpliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "def test_upper():\n",
      "    assert pgcd(42, 30) == 6\n",
      "\n",
      "def test_lower():\n",
      "    assert pgcd(30, 42) == 6\n"
     ]
    }
   ],
   "source": [
    "# un test dans sa forme la plus simple\n",
    "!cat tests/test_pgcd_pytest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test tests/test_pgcd_pytest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1 -- /Users/tparment/git/flotpython-slides/venv/bin/python3.7\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest.py::test_upper \u001b[32mPASSED\u001b[0m\u001b[36m                             [ 50%]\u001b[0m\n",
      "tests/test_pgcd_pytest.py::test_lower \u001b[32mPASSED\u001b[0m\u001b[36m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# et bien sûr toujours le mode bavard\n",
    "!py.test -v tests/test_pgcd_pytest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## attendre une exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "import pytest\n",
      "\n",
      "def test_zero():\n",
      "    with pytest.raises(ZeroDivisionError):\n",
      "        pgcd(12, 0)\n"
     ]
    }
   ],
   "source": [
    "# pour spécifier qu'une expression doit retourner une exception\n",
    "!cat tests/test_pgcd_pytest_raise.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest_raise.py \u001b[32m.\u001b[0m\u001b[36m                                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test tests/test_pgcd_pytest_raise.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## presque égal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {}
   },
   "outputs": [],
   "source": [
    "## almost-equal\n",
    "# pas trouvé de méthode native pytest pour cela\n",
    "# numpy a des outils pour le faire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = np.array([1e10, 1e-7])\n",
    "x2 = np.array([1.000001e10, 1e-8])\n",
    "np.isclose(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "x3 = 1.00001 * x1\n",
    "assert all(np.isclose(x1, x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS: apparemment cela est maintenant dans pytest 3.0\n",
    "# voir https://stackoverflow.com/questions/8560131/pytest-assert-almost-equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* mêmes possibilités que les autres frameworks\n",
    "* aussi disponibles avec \n",
    "  * les tests dans des classes\n",
    "  * ou directement dans le module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "class TestPgcd:\n",
      "\n",
      "    def setup(self):\n",
      "        print(\"setup\")\n",
      "\n",
      "    def teardown(self):\n",
      "        print(\"teardown\")\n",
      "\n",
      "    def setup_class(cls):\n",
      "        print(\"\\nclass-level setup {}\".format(cls.__name__))\n",
      "        \n",
      "    def teardown_class(cls):\n",
      "        print(\"\\nclass-level teardown {}\".format(cls.__name__))\n",
      "        \n",
      "    def setup_method(self, method):\n",
      "        print(\"method-level setup {}\".format(method.__name__))\n",
      "        \n",
      "    def teardown_method(self, method):\n",
      "        print(\"method-level teardown {}\".format(method.__name__))\n",
      "        \n",
      "    def test_upper(self):\n",
      "        assert pgcd(42, 30) == 6\n",
      "\n",
      "    def test_lower(self):\n",
      "        assert pgcd(30, 42) == 6\n"
     ]
    }
   ],
   "source": [
    "!cat tests/test_pgcd_pytest_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest_class.py \n",
      "class-level setup TestPgcd\n",
      "method-level setup test_upper\n",
      "setup\n",
      "\u001b[32m.\u001b[0mteardown\n",
      "method-level teardown test_upper\n",
      "method-level setup test_lower\n",
      "setup\n",
      "\u001b[32m.\u001b[0mteardown\n",
      "method-level teardown test_lower\n",
      "\n",
      "class-level teardown TestPgcd\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pareil que pour nose, en mettant -s on supprime la capture\n",
    "!py.test -s tests/test_pgcd_pytest_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from library.pgcd import pgcd\n",
      "\n",
      "def test_upper():\n",
      "    # broken test on purpose\n",
      "    assert pgcd(42, 30) == 7\n",
      "\n",
      "def test_lower():\n",
      "    assert pgcd(30, 42) == 6\n"
     ]
    }
   ],
   "source": [
    "# un exemple de sortie avec un test qui ne passe pas\n",
    "!cat tests/test_pgcd_pytest_broken.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.0, pytest-4.3.0, py-1.8.0, pluggy-0.8.1\n",
      "rootdir: /Users/tparment/git/flotpython-slides/slides-tests, inifile:\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_pgcd_pytest_broken.py \u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m__________________________________ test_upper __________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_upper():\u001b[0m\n",
      "\u001b[1m        # broken test on purpose\u001b[0m\n",
      "\u001b[1m>       assert pgcd(42, 30) == 7\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 6 == 7\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 6 = pgcd(42, 30)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_pgcd_pytest_broken.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m====================== 1 failed, 1 passed in 0.06 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pareil que pour nose, en mettant -s on supprime la capture\n",
    "!py.test -s tests/test_pgcd_pytest_broken.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### fixtures - suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* toute une ménagerie d'exemples [sur le site pytest](http://doc.pytest.org/en/latest/example/index.html)\n",
    "  * [commencer par notamment cette page sur les fixtures](http://doc.pytest.org/en/latest/fixture.html#fixtures)\n",
    "  * qui explique bien ...\n",
    "* les bases de l'exemple du projet minisim\n",
    "  * pour une fixture qui définit des variables globales\n",
    "  * [implémentée ici](https://gitlab.com/parmentelat/minisim2/blob/master/tests/conftest.py)\n",
    "* notez bien le fichier 'spécial' `conftest.py` qui est chargé automatiquement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# pratiques courantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* on place généralement les tests \n",
    "  * dans un directory `tests/`\n",
    "  * directement à la racine\n",
    "  * ou dans le package principal\n",
    "  * mais ce n'est pas une obligation\n",
    "* les tests unitaires sont groupés par module source, e.g.\n",
    "  * `minisim/zone.py`\n",
    "  * `tests/test_zone.py`\n",
    "* pour des tests de plus grande portée \n",
    "  * il n'y a pas spécialement d'usage \n",
    "  * le principal c'est de s'y retouver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* s'entraîner a lancer `py.test`\n",
    "  * sur un test précis\n",
    "  * sur tout un module de test\n",
    "\n",
    "* aller voir aussi les pipelines sur gitlab \n",
    "  * comment `py.test` est connecté à gitlab-ci\n",
    "  * où voir les résultats des tests\n",
    "  \n",
    "* peut-on améliorer les tests de minisim ?\n",
    "  * https://gitlab.com/parmentelat/minisim2\n",
    "  * fixtures ou pas fixtures ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `nose`\n",
    "\n",
    "> nose extends unittest to make testing easier\n",
    "\n",
    "> \"no boilerplate, some api\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## installation\n",
    "\n",
    "* sans surprise:\n",
    "\n",
    "```\n",
    "pip3 install nose\n",
    "```\n",
    "\n",
    "* expose la commande `nosetests` ($\\Longleftrightarrow$ `python3 -m nose`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!cat tests/test_pgcd_nose.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# lancer tous les tests dans un module\n",
    "!nosetests tests/test_pgcd_nose.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# idem en mode bavard\n",
    "!nosetests -v tests/test_pgcd_nose.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* On peut tout aussi bien faire des classes tout de même aussi\n",
    "  * toujours utile pour les fixtures\n",
    "  * mais aussi disponible à base de décorateurs\n",
    "  * gamme complète disponible\n",
    "* **ATTENTION** par défaut les outputs sont capturés\n",
    "  * utiliser `-s` pour éviter la capture\n",
    "* et toujours `-v`/`--verbose` pour le mode bavard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# des fixtures en utilisant une classe\n",
    "!cat tests/test_pgcd_nose_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# avec une classe\n",
    "!nosetests -v -s tests/test_pgcd_nose_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# des fixtures en utilisant un decorateur\n",
    "!cat tests/test_pgcd_nose_deco.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# on peut désigner un nom de fichier ou un module python\n",
    "!nosetests -v -s tests.test_pgcd_nose_deco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## langage d'assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### sous-tests\n",
    "\n",
    "```\n",
    "def test_evens():\n",
    "    for i in range(0, 5):\n",
    "        yield check_even, i, i*3\n",
    "\n",
    "def check_even(n, nn):\n",
    "    assert n % 2 == 0 or nn % 2 == 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# l'interface est la plus simple possible\n",
    "!nosetests -s tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## à noter\n",
    "\n",
    "* `nosetests` a trouvé les tests que nous avons écrit pour `nose`\n",
    "  * **et** ceux écrits en unittest !\n",
    "* dans l'environnement du cours j'ai beaucoup de bazar\n",
    "  * j'ai dû préciser `python3 -m unittest tests` \n",
    "  * sans préciser `testing` j'obtenais un gros crash\n",
    "  * alors que `nosetests` tout court fonctionne correctement\n",
    "* voir aussi [la doc complète sur readthedocs](http://nose.readthedocs.io/en/latest/testing.html)\n",
    "* on peut exécuter les tests `doctest` depuis `nose`\n",
    "* un système de plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://sametmax.com/un-gros-guide-bien-gras-sur-les-tests-unitaires-en-python-partie-1/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "notebookname": "NO HEADING 1 found",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "2",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "version": "1.0"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
