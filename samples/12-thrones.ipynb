{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"licence\">\n",
    "<span>Licence CC BY-NC-ND</span>\n",
    "<span>Thierry Parmentelat &amp; Arnaud Legout</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pagerank on a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pagerank* is a graph metric made famous by google that has been using it - at its beginning - to sort pages found in an internet search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what is pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in a valued and directed graph, [pagerank](https://en.wikipedia.org/wiki/PageRank) aims at describing something akin \"popularity\" for each vertex\n",
    "\n",
    "the model roughly goes as follows **(no damping)**\n",
    "\n",
    "* all vertices (pages in the cas of the Web) have an equal likelihood to be your starting point\n",
    "* at each step, you consider the outgoing links, and randomly pick one as your next step, with relative probabilities based on the outgoing weights\n",
    "\n",
    "pagerank is then defined on each vertex as the relative number of times that you'll have visited that vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above model has a flaw, as it does account for people actually restarting from scratch their path in the web  \n",
    "for that reason in practice the following model is more used **(with damping)**\n",
    "\n",
    "* all vertices (pages in the cas of the Web) have an equal likelihood to be your starting point\n",
    "* at each step, you would either\n",
    "  * with a **0.15** probability restart from a randomly picked vertex (with an equal likelihood) \n",
    "  * or otherwise pick your next vertex like in the original model, using outgoing weight relative probability\n",
    "  \n",
    "in this example the **damping factor** usually named $d$ is 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## getting data over http"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll implement pagerank in a completely different context: our - much smaller of course - input graph is about bondings between the characters of the *Game of Thrones* ecosystem\n",
    "\n",
    "original data reference was [found in this page](https://www.macalester.edu/~abeverid/thrones.html); further digging turned up identical github-hosted contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are tools in the standard Python library for this step  \n",
    "however it is often deemed too abstruse and many people use `requests` instead  \n",
    "[See complete documentation here.](https://requests.kennethreitz.org/en/master/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware that requests is NOT is the standard library\n",
    "# so you may need to run in the terminal:\n",
    "# \n",
    "# $ pip install requests\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL = \"https://www.macalester.edu/~abeverid/data/stormofswords.csv\"\n",
    "# identical on github\n",
    "URL = \"https://raw.githubusercontent.com/pupimvictor/NetworkOfThrones/master/stormofswords.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET contents using http\n",
    "request = requests.get(URL)\n",
    "\n",
    "csv = request.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv is a str object\n",
    "type(csv), len(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting into lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many lines\n",
    "lines = csv.split(\"\\n\")\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a glimpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# let's take a quick look\n",
    "line1, line2, line3, *ignore = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# turns ou first line is a header\n",
    "# that's expected in a csv file\n",
    "line1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# then we get regular data\n",
    "line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "line3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "*ignore, line_2, line_1 = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "line_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "line_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meaningful lines : a slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to expose an iterable over meaningful lines\n",
    "# (i.e. excluding the header line)\n",
    "# so using a slice springs to mind\n",
    "meaningful = lines[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *parsing* is about making that data programing-friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to turn this text object into something more programing-friendly  \n",
    "this stage is called *parsing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is [a module called `csv` in the standard library](https://docs.python.org/3/library/csv.html), that could come in handy for more complex cases  \n",
    "but here things are so simple, let's parse this data \"by hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting a line in pieces: `str.split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, line in enumerate(meaningful):\n",
    "    source, target, weight = line.split(',')\n",
    "    if index < 3:\n",
    "        print(f\"{source} → {weight} → {target}\")\n",
    "    else:\n",
    "        print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building a dictionary (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but let's build a dictionary of dictionaries instead\n",
    "# for that we iterate over the (meningful) lines again\n",
    "graph1 = {}\n",
    "for index, line in enumerate(meaningful):\n",
    "    source, target, weight = line.split(',')\n",
    "    if source not in graph1:\n",
    "        graph1[source] = {}\n",
    "    graph1[source][target] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so each value in the graph \n",
    "# in turn is a dictionary\n",
    "graph1['Aemon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** that in this first version, weights are stored as `str` objects; we'll improve this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building a dictionary (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in fact there's a slightly better way to do this  \n",
    "that instruction here \n",
    "```python\n",
    "    if source not in graph1:\n",
    "        graph1[source] = {}\n",
    "```\n",
    "is not so nice; we can get rid of it by using a `defaultdict` object\n",
    "\n",
    "`defaultdict` is a class that inherits the regular `dict` class;  \n",
    "a `defaultdict` of `list`s, for example, will automatically create a `list()` instance whenever one tries to access a missing key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is in the standard library, no need to pip install\n",
    "from collections import defaultdict\n",
    "\n",
    "# here our values are nested dicts\n",
    "graph = defaultdict(dict)\n",
    "\n",
    "for index, line in enumerate(meaningful):\n",
    "    source, target, weight = line.split(',')\n",
    "    # we take this chance to convert weight as an int\n",
    "    graph[source][target] = int(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['Aemon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random walk *vs* linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pagerank can be computed by linear algebraic methods - using a stochastic matrix to model the relative likelyhood to go to vertex $j$ knowning you're on $i$  \n",
    "\n",
    "however here we will compute an approximation by a monte-carlo simulation instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class PageRankWalker:\n",
    "    \n",
    "\n",
    "    def __init__(self, graph, damping=0.85):\n",
    "        self.graph = graph\n",
    "        self.damping = damping\n",
    "        # the vertex we are on\n",
    "        self.current = None\n",
    "        self.init_random()\n",
    "        \n",
    "\n",
    "    def init_random(self):\n",
    "        # for each vertex we prepare a list\n",
    "        # with the possible next vertices, each appearing \n",
    "        # as many times as the weight\n",
    "        # this way a random walk only needs to pick\n",
    "        # randomly in that list\n",
    "        self.weighted_dispatcher = defaultdict(list)\n",
    "        for source, links_dict in graph.items():\n",
    "            for target, weight in links_dict.items():\n",
    "                for _ in range(weight):\n",
    "                    self.weighted_dispatcher[source].append(target)\n",
    "        # same for when we restart, a list of all the vertices will do\n",
    "        self.restart_dispatcher = list(self.graph.keys())\n",
    "\n",
    "\n",
    "    def start_vertex(self):\n",
    "        \"\"\"\n",
    "        randomly picks a start vertex\n",
    "        with equal choices\n",
    "        \"\"\"\n",
    "        return random.choice(self.restart_dispatcher)\n",
    "\n",
    "\n",
    "    def next_vertex(self):\n",
    "        \"\"\"\n",
    "        randomly picks a successor from a current vertex\n",
    "        using the weights\n",
    "        \"\"\"\n",
    "        choices = self.weighted_dispatcher[self.current]\n",
    "        # when reaching a vertex with no outgoing edge\n",
    "        # we restart from scratch\n",
    "        if not choices:\n",
    "            return self.start_vertex()\n",
    "        else:\n",
    "            return random.choice(choices)\n",
    "\n",
    "        \n",
    "    def walk(self, nb_steps):\n",
    "        \"\"\"\n",
    "        simulates that number of steps\n",
    "        result is a dictionary with \n",
    "        vertices as key, \n",
    "        and as value number of steps spent in that vertex\n",
    "        \"\"\"\n",
    "        result = defaultdict(int)\n",
    "        self.current = self.start_vertex()\n",
    "        result[self.current] += 1\n",
    "        # we've alredy done one step, so remove 1 here\n",
    "        for _ in range(nb_steps-1):\n",
    "            r = random.random()\n",
    "            if r <= self.damping:\n",
    "                self.current = self.next_vertex()\n",
    "            else:\n",
    "                self.current = self.start_vertex()\n",
    "            result[self.current] += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walker = PageRankWalker(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "STEPS = 1000\n",
    "frequencies = walker.walk(STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sum of all values should be STEPS\n",
    "raincheck = sum(frequencies.values())\n",
    "raincheck == STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raincheck, STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts are not so good at sorting\n",
    "# let's use a list instead\n",
    "tuples = [ (vertex, count) for vertex, count in frequencies.items() ]\n",
    "tuples.sort(key = lambda tupl: tupl[1], reverse=True)\n",
    "\n",
    "tuples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make it reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(graph, steps):\n",
    "    walker = PageRankWalker(graph)\n",
    "    frequencies = walker.walk(steps)\n",
    "    tuples = [ (vertex, count) for vertex, count in frequencies.items() ]\n",
    "    tuples.sort(key = lambda tupl: tupl[1], reverse=True)\n",
    "    for character, count in tuples[:5]:\n",
    "        print(f\"{character} was visited {count} times i.e. {count/steps:02%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print(f\"{40*'-'}\")\n",
    "    monte_carlo(graph, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print(f\"{40*'-'}\")\n",
    "    monte_carlo(graph, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using [the graphviz library](https://graphviz.readthedocs.io/en/stable/examples.html) \n",
    "\n",
    "installing dependencies is a 2-step process\n",
    "\n",
    "* the binary tool; for that [see the project's page](https://graphviz.gitlab.io/download/);  \n",
    "  also be aware that most common linux distros do support *graphviz*,  \n",
    "  so you can install them with either `dnf` or `apt-get`;  \n",
    "  or `brew` if on MacOS\n",
    "\n",
    "* the Python wrapper that you can install with (surprise !)\n",
    "```bash\n",
    "pip install graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiGraph stands for Directed Graph\n",
    "# that's what we need since our graph is directed indeed\n",
    "\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv = Digraph('Characters of the Thrones', filename='thrones.gv')\n",
    "\n",
    "for source, weighted_dict in graph.items():\n",
    "    for target, weight in weighted_dict.items():\n",
    "        gv.edge(source, target, label=f\"{weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "gv.attr(rankdir='TB', size='12')\n",
    "gv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use the csv library to parse input\n",
    "* for scalability: the weights in a real graph can be much higher;  \n",
    "  a smarter implementation would remove the need for allocating the potentially large / huge lists in `weighted_dispatcher`"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "sphinx": {
    "toggle_input": true,
    "toggle_input_all": true,
    "toggle_output": true,
    "toggle_output_all": true
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notebookname": "pagerank on a graph",
  "version": "1.0"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
