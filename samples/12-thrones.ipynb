{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"licence\">\n",
    "<span>Licence CC BY-NC-ND</span>\n",
    "<span>Thierry Parmentelat &amp; Arnaud Legout</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pagerank on a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pagerank* is a graph metric made famous by Google, who has been using it - at its beginning - to sort pages found in an Internet search, so as to show most relevant pages first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what is pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in a valued and directed graph, each edge in the graph has an integer value attached to it\n",
    "\n",
    "for such graphs [pagerank](https://en.wikipedia.org/wiki/PageRank) aims at describing something akin \"popularity\" for each vertex\n",
    "\n",
    "### no damping\n",
    "the original **(no damping)** model roughly goes as follows\n",
    "\n",
    "* all vertices (pages in the case of the Web) have an equal likelihood to be your starting point\n",
    "* at each step, you consider the outgoing links, and randomly pick one as your next step, with relative probabilities based on the outgoing weights  \n",
    "  that is to say, if for instance your current vertex has three outgoing links, with weighs 20, 40 and 60, then the first neighbor has 1/6 likelihood to be the next one, and second and third neighbors have 1/3 and 1/2 respectively.\n",
    "\n",
    "pagerank is then defined on each vertex as the relative number of times that you'll have visited that vertex after an infinite random walk that follows those rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with damping\n",
    "\n",
    "the above model has a flaw, as it does not account for people actually restarting from scratch their path in the web; \n",
    "for that reason, in practice the following model **(with damping)** is more widely used \n",
    "\n",
    "* all vertices (pages in the cas of the Web) have an equal likelihood to be your starting point\n",
    "* at each step, you would either\n",
    "  * with a **0.15** probability restart from a randomly picked vertex (with an equal likelihood) \n",
    "  * or otherwise pick your next vertex like in the original model, using outgoing weight relative probability\n",
    "  \n",
    "in this example, we used a standard **damping factor** value of 85% (usually named $d$) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overview\n",
    "\n",
    "we are going to compute this measure on a graph\n",
    "\n",
    "instead of dealing with web pages, we will use a dataset that describes the graph of weighed **relationships between characters** in a novel related to the ***Game of Thrones*** saga;  \n",
    "but since a graph is a graph, we can apply the same algorithm to this one, and give each character a rank, that may be perceived as some sort of popularity.\n",
    "\n",
    "so in a nutshell we need to build a graph in memory, and use this to simulate the logic of the random walk described above; theory has proven that the measure should converge to a stable value, provided that simulation is long enough, and we will verify this experimentally.\n",
    "\n",
    "\n",
    "here are the steps that we will take to this end :\n",
    "\n",
    "1. **aquisition**  \n",
    "  1. get raw data over http, it is located here  \n",
    "    https://raw.githubusercontent.com/pupimvictor/NetworkOfThrones/master/stormofswords.csv  \n",
    "1. **parsing**  \n",
    "  1. understand what this data represents\n",
    "  1. design a data structure that can capture this information in a way that is convenient for the simulation that we want to run on the graph\n",
    "  1. build that data structure from the raw data obtained during first step\n",
    "1. **simulation**\n",
    "  1. pagerank can be computed by linear algebraic methods - using a stochastic matrix to model the relative likelyhood to go to vertex $j$ knowning you're on $i$; however in this exercise we want to do a simulation\n",
    "  1. so once this graph is ready, we can write a simulation tool that walks the graph randomly following the *rules of the game* explained above\n",
    "1. **observation** \n",
    "  1. running the simulation several times with different lifespans rangin from several hops to a few thousands, we can experimentally check if we indeed obtain consistent results, i.e. constant results for all characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for step **acquisition**\n",
    "\n",
    "* loading a csv as a pandas dataframe is a one-liner when using [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "\n",
    "* once you have a dataframe you will need to iterate on its rows  \n",
    "  this can be done like so (image the dataframe has columns LastName and FirstName)\n",
    "  \n",
    "  ```python\n",
    "  for i, line in df.iterrows():\n",
    "        print(f\"line number {i}, {line.FirstName} {line.LastName}\")\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "level_intermediate"
    ]
   },
   "source": [
    "Note that it is also possible to use [the `requests` library](https://requests.readthedocs.io/en/master/) to download the remote csv file right into memory\n",
    "\n",
    "Sine it is not part of the standard library, you need to install it with `pip install requests` \n",
    "\n",
    "so it all comes down to using `requests.get` to create a request object, and then read this object's `text` attribute to download the data\n",
    "\n",
    "it is an alternative approach that takes more steps to do the job (at you will need to load the file yourself) but may be more flexible in other similar situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for **parsing**\n",
    "\n",
    "the crucial part here is to imagine a data structure that depicts the graph; \n",
    "we will need to model 'vertices' in the graph in a way that can be easily walked.\n",
    "\n",
    "many data structures can do the job, and our suggestion here is to use a dictionary of dictionaries; like in the following example\n",
    "\n",
    "```\n",
    "test graph:\n",
    "   'A'   -- 10 ->  'B'\n",
    "   'A'   -- 20 ->  'C' \n",
    "   'B'   -- 30 ->  'C' \n",
    "   'B'   -- 40 ->  'D'\n",
    "   'D'   -- 20 ->  'A'\n",
    "```\n",
    "\n",
    "would then be represented by a dictionary that looks like this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {'A': {'B': 10, 'C': 20}, \n",
    "         'B': {'C': 30, 'D': 40},\n",
    "         'D': {'A': 20}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so to put it another way :\n",
    "* our graph's keys are the graph's vertices\n",
    "* the value attached (in the dictionary sense) to a vertex represents the outgoing links of that vertex\n",
    "\n",
    "so, because there is a link weighed 20 going from 'D' to 'A', we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['D']['A'] == 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "level_intermediate"
    ]
   },
   "source": [
    "if you'd rather go for using `requests` than `pandas`, one last word of warning about parsing:\n",
    "* you will start from a single `str` object (the raw data) that needs to be cut into lines first;  \n",
    "  for that, `str.split()` can do the job very well\n",
    "* however some of the lines obtained by this method may be either useless (there is often a first line with column names, and it is the case here too); the last line may be empty as well, so pay attention\n",
    "* for cutting a line into pieces, `str.split()` here again can do the job very nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for **simulating**\n",
    "\n",
    "of course you will need to [use the `ramdom` module](https://docs.python.org/3.7/library/random.html), and in particular `random.choice()` to pick in a list of choices. \n",
    "\n",
    "one way to think about this problem is to create a class `RandomWalker`:\n",
    "\n",
    "* initialization (`__init__` method)\n",
    "  * we create an instance from a graph-dictionary and a damping factor\n",
    "  * we also want to model the current vertex, so a `current` instance attribute comes in handy\n",
    "* initialization (continued) - `init_random()` method\n",
    "  * this is optional, but in order to speed up simulation, we may want to prepare data structures that are ready for that purpose; in particular, each time we run a simulation step (move the current vertex), we want to randomly pick the next vertex with relative probabilities in line with the outgoing weighs\n",
    "  * as a suggestion, these data structures could be (a) a list of all vertices in the graph, so that one can be picked randomly using `random.choice()` and (b) a dictionary of similar structures for each vertex when it comes to picking a neigh bour\n",
    "* pick a start vertex - `pick_start_vertex()` method\n",
    "  * returns a starting vertex with a uniform probability\n",
    "* pick a neighbour vertex - `pick_neighbor_vertex()` method\n",
    "  * from the current vertex, return a neighbour picked randomly with the probabilities defined by their outgoing weighs.\n",
    "* simulate the graph for some number of steps - `walk()` method\n",
    "  * from all the above, it is easy to write the simulation\n",
    "  * result is a dictionary with vertices as key, and as value \n",
    "    the number of steps spent in that vertex during the simulation\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/pupimvictor/NetworkOfThrones/master/stormofswords.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# insert new cells with Alt-Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class PageRankWalker:\n",
    "    \n",
    "\n",
    "    def __init__(self, graph, damping=0.85):\n",
    "        self.graph = graph\n",
    "        self.damping = damping\n",
    "        # current vertex\n",
    "        self.current = None\n",
    "        self.init_random()\n",
    "        \n",
    "\n",
    "    def init_random(self):\n",
    "        \"\"\"\n",
    "        initialize whatever data structures \n",
    "        you think can speed up simulation\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "\n",
    "    def pick_start_vertex(self):\n",
    "        \"\"\"\n",
    "        randomly picks a start vertex\n",
    "        with equal choices\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def pick_next_vertex(self):\n",
    "        \"\"\"\n",
    "        randomly picks a successor from current vertex\n",
    "        using the weights\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "        \n",
    "    def walk(self, nb_steps):\n",
    "        \"\"\"\n",
    "        simulates that number of steps\n",
    "        result is a dictionary with \n",
    "        vertices as key, \n",
    "        and as value number of steps spent in that vertex\n",
    "        \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "RUNNING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a walker object from the graph obtained above\n",
    "walker = PageRankWalker(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "STEPS = 1000\n",
    "frequencies = walker.walk(STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sum of all values should be STEPS\n",
    "raincheck = sum(frequencies.values())\n",
    "raincheck == STEPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raincheck, STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts are not so good at sorting\n",
    "# let's use a list instead\n",
    "\n",
    "tuples = [ (vertex, count) for vertex, count in frequencies.items() ]\n",
    "tuples.sort(key = lambda tupl: tupl[1], reverse=True)\n",
    "\n",
    "tuples[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make it reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def monte_carlo(graph, steps):\n",
    "    \"\"\"\n",
    "    run a simulation over that number of steps\n",
    "    \"\"\"\n",
    "    walker = PageRankWalker(graph)\n",
    "    # simulate\n",
    "    frequencies = walker.walk(steps)\n",
    "    # retrieve result\n",
    "    tuples = [ (vertex, count) for vertex, count in frequencies.items() ]\n",
    "    # sort on highest occurrences first\n",
    "    tuples.sort(key = lambda tupl: tupl[1], reverse=True)\n",
    "    # display 5 most items\n",
    "    for character, count in tuples[:5]:\n",
    "        print(f\"{character} was visited {count} times i.e. {count/steps:02%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top winners with a 1000-steps simu\n",
    "for _ in range(5):\n",
    "    print(f\"{40*'-'}\")\n",
    "    monte_carlo(graph, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with a tenfold simulation\n",
    "for _ in range(5):\n",
    "    print(f\"{40*'-'}\")\n",
    "    monte_carlo(graph, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using [the graphviz library](https://graphviz.readthedocs.io/en/stable/examples.html) \n",
    "\n",
    "installing dependencies is a 2-step process\n",
    "\n",
    "* the binary tool; for that [see the project's page](https://graphviz.gitlab.io/download/);  \n",
    "  also be aware that most common linux distros do support *graphviz*,  \n",
    "  so you can install them with either `dnf` or `apt-get`;  \n",
    "  or `brew` if on MacOS\n",
    "\n",
    "* the Python wrapper that you can install with (surprise !)\n",
    "```bash\n",
    "pip install graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiGraph stands for Directed Graph\n",
    "# that's what we need since our graph is directed indeed\n",
    "\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv = Digraph('Characters of the Thrones', filename='thrones.gv')\n",
    "\n",
    "for source, weighted_dict in graph.items():\n",
    "    for target, weight in weighted_dict.items():\n",
    "        gv.edge(source, target, label=f\"{weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "gv.attr(rankdir='TB', size='12')\n",
    "gv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use the csv library to parse input\n",
    "* for scalability: the weights in a real graph can be much higher;  \n",
    "  a smarter implementation would remove the need for allocating the potentially large / huge lists in `weighted_dispatcher`"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "sphinx": {
    "toggle_input": true,
    "toggle_input_all": true,
    "toggle_output": true,
    "toggle_output_all": true
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notebookname": "pagerank on a graph",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "version": "1.0"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
